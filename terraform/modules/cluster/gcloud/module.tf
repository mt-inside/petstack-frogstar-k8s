resource "google_project" "project" {
    name = "${var.cluster_name}"
    project_id = "${var.cluster_name}"
    billing_account = "${var.gcloud_billing_account}" /* account to which to charge. Won't do much without one. */
}

resource "google_project_service" "compute_api" {
    depends_on = [ "google_project.project" ]

    project = "${var.cluster_name}"
    service = "compute.googleapis.com"
}
resource "google_project_service" "cluster_api" {
    depends_on = [ "google_project.project" ]

    project = "${var.cluster_name}"
    service = "container.googleapis.com"
}

/* Just makes the control plane(?). See node pools comments */
resource "google_container_cluster" "cluster" {
    depends_on = [ "google_project_service.compute_api", "google_project_service.cluster_api" ]

    project = "${google_project.project.number}"
    name = "${var.cluster_name}"
    zone = "${var.gcloud_zone}"

    /* Node pool handling is bad. Options
    * - Give initial_node_count. This makes a default pool. Can specify
    * /some/ other options for it in the cluster resource (e.g. node_config),
    * but not everything e.g. autoscaling.
    * - Specify separate "google_container_node_pool" resources. These have
    * a cluster name and ADD pools to it. They have the same schema as the
    * in-line node_pool below, but also need project and zone. Nothing you can
    * do to prevent the default pool being made in this case. People describle
    * having a null_resource to delete the default pool: https://www.bountysource.com/issues/51832667-not-possible-to-use-google_container_node_pool-without-the-default-node-pool
    * - Have an array of node_pools in-line, as below. Slightly clunky, but
    * prevents the creation of the default node pool. Mutex with
    * initial_node_count
    */
    node_pool = [
        {
            name = "ondemand"

            node_count = 1
            autoscaling {
                min_node_count = 1
                max_node_count = 5
            }

            node_config {
                disk_size_gb = 100
                machine_type = "n1-standard-1"
                preemptible = false
                oauth_scopes = [
                    /* GCE API access from the Nodes' default (GCE?) service
                    * accounts. This is the standard gcloud console set */

                    /* Necessary */
                    "https://www.googleapis.com/auth/compute",
                    "https://www.googleapis.com/auth/devstorage.read_only",
                    "https://www.googleapis.com/auth/logging.write",
                    "https://www.googleapis.com/auth/monitoring",
                    /* Optional */
                    "https://www.googleapis.com/auth/service.management.readonly",
                    "https://www.googleapis.com/auth/servicecontrol",
                    "https://www.googleapis.com/auth/trace.append",
                ]
            }
        }
    ]

    //cluster_ipv4_cidr = "10.244.0.0/16" Doesn't seem to work, maybe not the pod network option I thought

    addons_config {
        horizontal_pod_autoscaling {
            /* Can't really disable this as it's a controller-manager
            * option, not something that can be installed after the fact */
            disabled = false
        }
        http_load_balancing {
            /* shitty GCE ingress controller */
            disabled = true
        }
        kubernetes_dashboard {
            /* TODO disable? as can be installed manually for consistency */
            disabled = false
        }
    }

    /* GUI-made clusters get this too. HTTP basic auth for talking to the
    * API server. Ideally want to turn basic auth off altogehter but can't
    * see an option; think this passwd will just get autogenerated if not
    * specified */
    /*master_auth {
        username = "admin"
        password = "fTjqHAMvGh4XSyhX"
    }*/

    provisioner "local-exec" {
        command = "gcloud --project ${var.cluster_name} container clusters get-credentials ${var.cluster_name}"
    }
}
